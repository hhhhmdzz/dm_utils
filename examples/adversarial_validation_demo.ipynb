{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/titanic/train.csv').drop('PassengerId', axis=1)\n",
    "test_data = pd.read_csv('../data/titanic/test.csv').drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\n",
    "test_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n",
    "test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].median())\n",
    "train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.')\n",
    "test_data['Title'] = test_data['Name'].str.extract(' ([A-Za-z]+)\\.')\n",
    "rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "train_data['Title'] = train_data['Title'].replace(rare_titles, 'Rare')\n",
    "test_data['Title'] = test_data['Title'].replace(rare_titles, 'Rare')\n",
    "for col in ['Sex', 'Embarked', 'Title']:\n",
    "    encoder = LabelEncoder()\n",
    "    train_data[col] = encoder.fit_transform(train_data[col])\n",
    "    test_data[col] = encoder.transform(test_data[col])\n",
    "train_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = train_data.drop('Survived', axis=1), train_data['Survived']\n",
    "xtest, ytest = test_data.drop('Survived', axis=1), test_data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Validation with Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7655502392344498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(xtrain, ytrain)\n",
    "print(lr.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7002583979328165 2 ['Age', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "from dm_utils.utils.feas import adversarial_validation_features\n",
    "\n",
    "total_drop_feas = []\n",
    "auc, train_proba, drop_feas, remain_feas = adversarial_validation_features(xtrain, xtest, drop_n=2)\n",
    "print(auc, len(drop_feas), drop_feas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49825581395348834 ['Parch']\n"
     ]
    }
   ],
   "source": [
    "total_drop_feas.extend(drop_feas)\n",
    "auc, train_proba, drop_feas, remain_feas = adversarial_validation_features(\n",
    "    xtrain.drop(columns=total_drop_feas), xtest.drop(columns=total_drop_feas), drop_n=1)\n",
    "print(auc, drop_feas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7751196172248804\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(xtrain.drop(columns=total_drop_feas), ytrain)\n",
    "print(lr.score(xtest.drop(columns=total_drop_feas), ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Validation with Insances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "val_size = 0.1\n",
    "xtrn, xval, ytrn, yval = train_test_split(xtrain, ytrain, test_size=val_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.381167\n",
      "[200]\tvalid_0's binary_logloss: 0.434686\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.362309\n",
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "\n",
    "callbacks = [log_evaluation(100), early_stopping(stopping_rounds=200)]\n",
    "lgb = LGBMClassifier(n_estimators=1000, random_state=42, verbosity=-1)\n",
    "lgb.fit(xtrn, ytrn, eval_set=[(xval, yval)], callbacks=callbacks)\n",
    "print(lgb.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7002583979328165\n"
     ]
    }
   ],
   "source": [
    "from dm_utils.utils.feas import adversarial_validation_instances\n",
    "\n",
    "auc, train_proba, select_idx, remain_idx = adversarial_validation_instances(xtrain, xtest, select_rate=val_size)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6335441132189099\n"
     ]
    }
   ],
   "source": [
    "xtrn, xval, ytrn, yval = xtrain.iloc[remain_idx], xtrain.iloc[select_idx], ytrain.iloc[remain_idx], ytrain.iloc[select_idx]\n",
    "auc, train_proba, select_idx, remain_idx = adversarial_validation_instances(xtrn, xtest, select_rate=val_size)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.421807\n",
      "[200]\tvalid_0's binary_logloss: 0.576956\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's binary_logloss: 0.349692\n",
      "0.7535885167464115\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(n_estimators=1000, random_state=42, verbosity=-1)\n",
    "lgb.fit(xtrn, ytrn, eval_set=[(xval, yval)], callbacks=callbacks)\n",
    "print(lgb.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
